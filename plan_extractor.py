"""
This script processes a log file generated by a Terraform plan and extracts specific information 
about resources that will be deprecated/errored, created, destroyed, or updated. The extracted information 
is then written to a CSV file in a structured format.

The script identifies the following types of changes in the log file:
- Deprecated warnings
- Resources to be added
- Resources to be destroyed
- Resources to be updated


Usage:
  python plan_extractor.py <log_file> <csv_file> <provider> <version>

Notes:
  - The script expects the log file to follow a specific format, such as lines starting with 
    specific markers (e.g., "#", "│") to identify resource changes or warnings.
  - Deprecated warnings are handled separately and grouped under a "deprecated" category.
  - The output CSV file is appended to if it already exists.
"""
import re
import csv
import argparse
import sys

def read_log_file(log_file):
    try:
        with open(log_file, 'r') as f:
            return f.readlines()
    except FileNotFoundError:
        print(f"Error: Log file '{log_file}' not found.")
        sys.exit(1)
    except IOError as e:
        print(f"Error reading log file: {e}")
        sys.exit(1)

def process_log_file(log_file, csv_file, provider, version):
    patterns = {
        "add": re.compile(r'^# .* will be created$'),
        "destroy": re.compile(r'^# .* will be destroyed$'),
        "update": re.compile(r'^# .* will be updated in-place$')
    }
    groups = {"add": [], "destroy": [], "update": [], "deprecated": []}
    current_group = []
    current_type = None

    lines = read_log_file(log_file)

    for line in lines:
        stripped_line = line.strip()
        matched_type = next((key for key, pattern in patterns.items() if pattern.match(stripped_line)), None)

        if matched_type:
            if current_group and current_type:
                groups[current_type].append("".join(current_group))
            current_group = [line]
            current_type = matched_type
        elif line.startswith("│"):
            # Handle deprecated warnings
            if "Warning: Argument is deprecated" in line:
                # Only add a blank line if the last line is not already blank and not the first line
                if groups["deprecated"] and groups["deprecated"][-1].strip() != "":
                    groups["deprecated"].append("")
            groups["deprecated"].append(line.replace('│', '').strip())
        elif line.startswith("#") or line.startswith("Plan:"):
            if current_group and current_type:
                groups[current_type].append("".join(current_group)) 
                current_group = []
                current_type = None
        else:
            if current_type:  # Only append to the current group if it has a valid type
                current_group.append(line) 

    if current_group and current_type:
        groups[current_type].append("".join(current_group))

    write_to_csv(csv_file, groups, provider, version)

def write_to_csv(csv_file, groups, provider, version):
    try:
        with open(csv_file, 'a', newline='') as f:
            writer = csv.writer(f)
            writer.writerow([
                provider, version, 'FAILURE',
                "\n".join(groups["deprecated"]).replace('"', '""'),
                "\n\n".join(groups["add"]).replace('"', '""'),
                "\n\n".join(groups["destroy"]).replace('"', '""'),
                "\n\n".join(groups["update"]).replace('"', '""')
            ])
    except IOError as e:
        print(f"Error writing to CSV file: {e}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Process log file and generate CSV.")
    parser.add_argument('log_file', help="Path to the log file")
    parser.add_argument('csv_file', help="Path to the output CSV file")
    parser.add_argument('provider', help="Name of provider")
    parser.add_argument('version', help="Version of provider")
    args = parser.parse_args()

    process_log_file(args.log_file, args.csv_file, args.provider, args.version)